{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18549,"status":"ok","timestamp":1749416769122,"user":{"displayName":"최승규","userId":"10957631576951172627"},"user_tz":-540},"id":"wAurzZAFgX_H","outputId":"7627339e-531b-4537-cbc9-61bb28a8b616"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2154,"status":"ok","timestamp":1749416771279,"user":{"displayName":"최승규","userId":"10957631576951172627"},"user_tz":-540},"id":"UMXGPfb4-FIc","outputId":"b0bacb6a-5f5b-425c-ef7e-7aa0656b1635"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'public_cs224n_gpt'...\n","remote: Enumerating objects: 69, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 69 (delta 21), reused 13 (delta 13), pack-reused 31 (from 1)\u001b[K\n","Receiving objects: 100% (69/69), 30.87 MiB | 29.17 MiB/s, done.\n","Resolving deltas: 100% (22/22), done.\n","/content/public_cs224n_gpt\n"]}],"source":["!git clone https://github.com/ItWasAllYellow/public_cs224n_gpt.git\n","%cd public_cs224n_gpt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480934,"status":"ok","timestamp":1749415301821,"user":{"displayName":"최승규","userId":"10957631576951172627"},"user_tz":-540},"id":"n6D4C3-htG5S","outputId":"7f3288fd-41b9-4bf2-e2f1-3ec0d4ac1220"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 1: 100%|██████████| 36/36 [00:22<00:00,  1.58it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 | Loss: 655292.4014 | Dev Top1/2/3: 0.2222/0.5000/0.6111 | PPL: 410022.9861\n","Saved model to /content/drive/MyDrive/CSEG321/models/answer_margin_gpt2_20e_5e-05lr.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 2: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 | Loss: 14616.7176 | Dev Top1/2/3: 0.2222/0.5000/0.6667 | PPL: 324473.6424\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 3: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 | Loss: 10014.4197 | Dev Top1/2/3: 0.1667/0.4444/0.6667 | PPL: 287841.7986\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 4: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 | Loss: 6158.5101 | Dev Top1/2/3: 0.1667/0.4444/0.6111 | PPL: 266362.0955\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 5: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 | Loss: 7479.2651 | Dev Top1/2/3: 0.1667/0.4444/0.6667 | PPL: 244116.0069\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 6: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 | Loss: 6509.7757 | Dev Top1/2/3: 0.1667/0.3889/0.6111 | PPL: 224857.0226\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 7: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 | Loss: 5731.4290 | Dev Top1/2/3: 0.1667/0.4444/0.5556 | PPL: 207631.5660\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 8: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 | Loss: 4531.2536 | Dev Top1/2/3: 0.1667/0.4444/0.5556 | PPL: 195381.7326\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 9: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 | Loss: 5592.2475 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 182302.9340\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 10: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 | Loss: 5107.2027 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 169638.4948\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 11: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 | Loss: 4476.1131 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 158921.4809\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 12: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 | Loss: 3964.3289 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 150580.7370\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 13: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 | Loss: 4219.7947 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 141303.5443\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 14: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 | Loss: 3073.9286 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 136156.4844\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 15: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 | Loss: 3942.9524 | Dev Top1/2/3: 0.2222/0.4444/0.5556 | PPL: 129626.9080\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 16: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 | Loss: 2915.5466 | Dev Top1/2/3: 0.2222/0.4444/0.6111 | PPL: 124414.7873\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 17: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 | Loss: 2727.9395 | Dev Top1/2/3: 0.2222/0.3889/0.7222 | PPL: 120183.7587\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 18: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 | Loss: 2547.3020 | Dev Top1/2/3: 0.2222/0.3889/0.7222 | PPL: 115745.5825\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 19: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 | Loss: 2866.0914 | Dev Top1/2/3: 0.2222/0.4444/0.7222 | PPL: 111889.1415\n"]},{"name":"stderr","output_type":"stream","text":["Train Epoch 20: 100%|██████████| 36/36 [00:22<00:00,  1.60it/s]\n","Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 | Loss: 2305.1473 | Dev Top1/2/3: 0.2222/0.4444/0.7222 | PPL: 108137.4618\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\"\"\"\n","Answer Margin Ranking Trainer\n","\n","Trains a GPT-2 based model to rank multiple-choice answers by minimizing margin loss\n","on perplexity scores. Generates Top-1/2/3 accuracy and average perplexity on dev/test splits.\n","\"\"\"\n","\n","import argparse\n","import os\n","import random\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from transformers import GPT2Tokenizer\n","from models.gpt2 import GPT2Model      # public_cs224n_gpt implementation\n","from transformers import GPT2LMHeadModel\n","\n","# suppress TQDM if needed\n","TQDM_DISABLE = False\n","\n","def seed_everything(seed: int = 42):\n","    \"\"\"Fix random seeds for reproducibility.\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","class AnswerMarginModel(nn.Module):\n","    \"\"\"Wrapper around GPT2Model + LM head for computing token logits.\"\"\"\n","    def __init__(self, args):\n","        super().__init__()\n","        # backbone\n","        self.gpt = GPT2Model.from_pretrained(\n","            model=args.model_size,\n","            d=args.d,\n","            l=args.l,\n","            num_heads=args.num_heads\n","        )\n","        # LM head\n","        self.lm_head = nn.Linear(args.d, GPT2Tokenizer.from_pretrained(args.model_size).vocab_size, bias=False)\n","        # fine-tune everything\n","        for p in self.gpt.parameters():\n","            p.requires_grad = True\n","        for p in self.lm_head.parameters():\n","            p.requires_grad = True\n","\n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"Returns token-level logits of shape (B, T, V).\"\"\"\n","        out = self.gpt(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden = out[\"last_hidden_state\"]\n","        logits = self.lm_head(hidden)\n","        return logits\n","\n","def calculate_perplexity(logits, labels, attention_mask):\n","    \"\"\"\n","    Compute per-example perplexity:\n","    - logits: (B*T, V)\n","    - labels & mask: (B*T)\n","    Returns perp of shape (B*T) then can be reshaped.\n","    \"\"\"\n","    shift_logits = logits[..., :-1, :].contiguous()\n","    shift_labels = labels[..., 1:].contiguous()\n","    shift_mask   = attention_mask[..., 1:].contiguous()\n","\n","    loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n","    loss = loss_fn(shift_logits.view(-1, shift_logits.size(-1)),\n","                   shift_labels.view(-1))\n","    loss = loss.view_as(shift_labels)\n","    loss = loss * shift_mask\n","\n","    sum_loss = loss.sum(dim=1)\n","    token_count = shift_mask.sum(dim=1).clamp_min(1)\n","    mean_loss = sum_loss / token_count\n","    return torch.exp(mean_loss)\n","\n","class MarginLoss(nn.Module):\n","    \"\"\"Hinge-style margin loss between correct and incorrect PPLs.\"\"\"\n","    def __init__(self, margin: float = 1.0):\n","        super().__init__()\n","        self.margin = margin\n","\n","    def forward(self, correct_ppl, incorrect_ppls):\n","        # correct: (B,), incorrect: (B, C-1)\n","        correct = correct_ppl.unsqueeze(1).expand_as(incorrect_ppls)\n","        loss = F.relu(correct - incorrect_ppls + self.margin)\n","        return loss.mean()\n","\n","class AnswerMarginDataset(Dataset):\n","    \"\"\"Dataset for packing 5 candidate texts per example.\"\"\"\n","    def __init__(self, df: pd.DataFrame, tokenizer: GPT2Tokenizer, max_length: int = 512):\n","        self.df = df.reset_index(drop=True)\n","        self.tok = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        prefix = row[\"prefix\"]\n","        suffix = row[\"suffix\"]\n","        choices = [row[f\"choice_{i}\"] for i in range(1,6)]\n","        example_texts = [f\"{prefix}{c}{suffix}\" for c in choices]\n","        label = int(row[\"answer\"]) - 1\n","        return example_texts, label\n","\n","    def collate_fn(self, batch):\n","        texts, labels = zip(*batch)\n","        flat_texts = sum(texts, [])\n","        enc = self.tok.batch_encode_plus(\n","            flat_texts,\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=self.max_length,\n","            return_tensors=\"pt\"\n","        )\n","        B = len(batch)\n","        input_ids = enc[\"input_ids\"].view(B, 5, -1)\n","        attention_mask = enc[\"attention_mask\"].view(B, 5, -1)\n","        return {\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"labels\": torch.tensor(labels, dtype=torch.long)\n","        }\n","\n","def load_data(path: str, split: str = None):\n","    \"\"\"Load CSV and optionally filter by split column.\"\"\"\n","    df = pd.read_csv(path, encoding=\"utf-8-sig\")\n","    return df[df.split == split].reset_index(drop=True) if split else df\n","\n","def save_model(model: nn.Module, optimizer, args, path: str):\n","    \"\"\"Persist the model + optimizer state.\"\"\"\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    torch.save({\n","        \"model\": model.state_dict(),\n","        \"optim\": optimizer.state_dict(),\n","        \"args\": args\n","    }, path)\n","    print(f\"Saved model to {path}\")\n","\n","def evaluate(dataloader, model, lm_head_model, device):\n","    \"\"\"Compute Top-1/2/3 accuracies and average PPL on a split.\"\"\"\n","    model.eval()\n","    total = top1 = top2 = top3 = 0\n","    total_ppl = 0.0\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\", disable=TQDM_DISABLE):\n","            B, C, L = batch[\"input_ids\"].shape\n","            ids = batch[\"input_ids\"].view(B*C, L).to(device)\n","            mask = batch[\"attention_mask\"].view(B*C, L).to(device)\n","            logits = model(ids, mask)\n","            ppl = calculate_perplexity(logits, ids, mask).view(B, C)\n","\n","            total += B\n","            ranked = torch.argsort(ppl, dim=1)\n","            labels = batch[\"labels\"].to(device)\n","            top1 += (ranked[:,0] == labels).sum().item()\n","            top2 += ((ranked[:,:2] == labels.unsqueeze(1)).any(1)).sum().item()\n","            top3 += ((ranked[:,:3] == labels.unsqueeze(1)).any(1)).sum().item()\n","            total_ppl += ppl.mean().item() * B\n","\n","    return top1/total, top2/total, top3/total, total_ppl/total\n","\n","def train(args):\n","    \"\"\"Main training loop for Margin Ranking.\"\"\"\n","    seed_everything(args.seed)\n","    device = torch.device(\"cuda\" if args.use_gpu and torch.cuda.is_available() else \"cpu\")\n","    print(f\"Using device: {device}\")\n","\n","    # prepare data\n","    train_df = load_data(args.data_path, \"train\")\n","    dev_df   = load_data(args.data_path, \"valid\")\n","\n","    tokenizer = GPT2Tokenizer.from_pretrained(args.model_size)\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","    train_ds = AnswerMarginDataset(train_df, tokenizer, args.max_length)\n","    dev_ds   = AnswerMarginDataset(dev_df, tokenizer, args.max_length)\n","\n","    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,\n","                              collate_fn=train_ds.collate_fn)\n","    dev_loader   = DataLoader(dev_ds, batch_size=args.batch_size, shuffle=False,\n","                              collate_fn=dev_ds.collate_fn)\n","\n","    model = AnswerMarginModel(args).to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n","    loss_fn = MarginLoss(margin=args.margin)\n","\n","    best_top1 = 0.0\n","    for epoch in range(1, args.epochs+1):\n","        model.train()\n","        epoch_loss = 0.0\n","        for batch in tqdm(train_loader, desc=f\"Train Epoch {epoch}\", disable=TQDM_DISABLE):\n","            optimizer.zero_grad()\n","            B, C, L = batch[\"input_ids\"].shape\n","            ids = batch[\"input_ids\"].view(B*C, L).to(device)\n","            mask = batch[\"attention_mask\"].view(B*C, L).to(device)\n","            logits = model(ids, mask)\n","            ppl = calculate_perplexity(logits, ids, mask).view(B, C)\n","            correct = ppl[torch.arange(B), batch[\"labels\"].to(device)]\n","            wrongs = torch.stack([ppl[i, torch.arange(C)!=batch[\"labels\"][i]] for i in range(B)])\n","            loss = loss_fn(correct, wrongs)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item()\n","\n","        avg_loss = epoch_loss / len(train_loader)\n","        top1, top2, top3, avg_ppl = evaluate(dev_loader, model, None, device)\n","        print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | Dev Top1/2/3: {top1:.4f}/{top2:.4f}/{top3:.4f} | PPL: {avg_ppl:.4f}\")\n","\n","        # checkpoint\n","        if top1 > best_top1:\n","            best_top1 = top1\n","            save_model(model, optimizer, args, args.save_path)\n","\n","def get_args():\n","    \"\"\"Parse command-line arguments (ignores Jupyter args).\"\"\"\n","    p = argparse.ArgumentParser()\n","    p.add_argument(\"--data_path\",    type=str, default=\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\")\n","    p.add_argument(\"--model_size\",   type=str, default=\"gpt2\", choices=[\"gpt2\",\"gpt2-medium\",\"gpt2-large\"])\n","    p.add_argument(\"--batch_size\",   type=int, default=4)\n","    p.add_argument(\"--max_length\",   type=int, default=512)\n","    p.add_argument(\"--lr\",           type=float, default=5e-5)\n","    p.add_argument(\"--epochs\",       type=int, default=20)\n","    p.add_argument(\"--margin\",       type=float, default=1000.0)\n","    p.add_argument(\"--seed\",         type=int, default=42)\n","    p.add_argument(\"--use_gpu\",      action=\"store_true\")\n","    # Jupyter friendly\n","    args = p.parse_args([])\n","    if torch.cuda.is_available(): args.use_gpu = True\n","    # set model dims\n","    if args.model_size == \"gpt2\":\n","        args.d, args.l, args.num_heads = 768,12,12\n","    elif args.model_size == \"gpt2-medium\":\n","        args.d, args.l, args.num_heads = 1024,24,16\n","    else:\n","        args.d, args.l, args.num_heads = 1280,36,20\n","    # save path\n","    args.save_path = f\"/content/drive/MyDrive/CSEG321/models/answer_margin_{args.model_size}_{args.epochs}e_{args.lr}lr.pt\"\n","    return args\n","\n","if __name__ == \"__main__\":\n","    args = get_args()\n","    train(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"w0VePl7Z_v9C","outputId":"968c5f53-099e-4a92-a63b-10eb560b89f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["Train 1: 100%|██████████| 36/36 [00:22<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1  loss=1.6539\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.278/0.667/0.778  AvgNLL=17.481\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_nll_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train 2: 100%|██████████| 36/36 [00:22<00:00,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2  loss=1.6049\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.333/0.611/0.833  AvgNLL=16.995\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_nll_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train 3: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3  loss=1.5719\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.556/0.833  AvgNLL=17.003\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_nll_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train 4: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4  loss=1.5010\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.333/0.556/0.778  AvgNLL=20.106\n"]},{"name":"stderr","output_type":"stream","text":["Train 5: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5  loss=1.5038\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.611/0.778  AvgNLL=22.044\n"]},{"name":"stderr","output_type":"stream","text":["Train 6: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6  loss=1.4081\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.333/0.667/0.889  AvgNLL=22.764\n"]},{"name":"stderr","output_type":"stream","text":["Train 7: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7  loss=1.2752\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.500/0.667/0.833  AvgNLL=23.807\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_nll_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train 8: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8  loss=1.1716\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.778/0.833  AvgNLL=25.030\n"]},{"name":"stderr","output_type":"stream","text":["Train 9: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9  loss=1.2209\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.500/0.722/0.889  AvgNLL=26.052\n"]},{"name":"stderr","output_type":"stream","text":["Train 10: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10  loss=1.0447\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.722/0.778  AvgNLL=27.357\n"]},{"name":"stderr","output_type":"stream","text":["Train 11: 100%|██████████| 36/36 [00:22<00:00,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11  loss=0.9033\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.333/0.778/0.889  AvgNLL=28.611\n"]},{"name":"stderr","output_type":"stream","text":["Train 12: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12  loss=0.8590\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.611/0.722  AvgNLL=34.321\n"]},{"name":"stderr","output_type":"stream","text":["Train 13: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13  loss=0.7393\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.278/0.667/0.778  AvgNLL=31.605\n"]},{"name":"stderr","output_type":"stream","text":["Train 14: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14  loss=0.7859\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.667/0.722  AvgNLL=33.293\n"]},{"name":"stderr","output_type":"stream","text":["Train 15: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15  loss=0.6568\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.611/0.889  AvgNLL=34.517\n"]},{"name":"stderr","output_type":"stream","text":["Train 16: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16  loss=0.5888\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.611/0.833  AvgNLL=35.177\n"]},{"name":"stderr","output_type":"stream","text":["Train 17: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17  loss=0.5656\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.611/0.833  AvgNLL=38.773\n"]},{"name":"stderr","output_type":"stream","text":["Train 18: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18  loss=0.4887\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.611/0.944  AvgNLL=40.133\n"]},{"name":"stderr","output_type":"stream","text":["Train 19: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19  loss=0.5030\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.556/0.778  AvgNLL=36.462\n"]},{"name":"stderr","output_type":"stream","text":["Train 20: 100%|██████████| 36/36 [00:22<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20  loss=0.4280\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:01<00:00,  4.98it/s]"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.667/0.778  AvgNLL=38.343\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\"\"\"\n","NLL-Ranking Trainer\n","\n","Trains a GPT-2 model to pick the correct option by minimizing cross-entropy\n","on Negative-Log-Likelihood scores. Top-1/2/3 accuracy + average NLL.\n","\"\"\"\n","\n","import argparse, os, random, sys, math\n","import numpy as np, pandas as pd, torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from transformers import GPT2Tokenizer\n","from models.gpt2 import GPT2Model     # custom GPT-2 implementation\n","\n","TQDM_DISABLE = False  # set True in Colab if bar flickers\n","\n","# --------------------------------------------------------------------- #\n","# 0. Utils\n","# --------------------------------------------------------------------- #\n","def seed_everything(seed: int = 42):\n","    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n","    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","# --------------------------------------------------------------------- #\n","# 1. Dataset\n","# --------------------------------------------------------------------- #\n","class AnswerDataset(Dataset):\n","    def __init__(self, df: pd.DataFrame, tokenizer: GPT2Tokenizer, max_len=512):\n","        self.df, self.tok, self.max_len = df.reset_index(drop=True), tokenizer, max_len\n","\n","    def __len__(self): return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        choices = [row[f\"choice_{i}\"] for i in range(1, 6)]\n","        texts   = [f\"{row.prefix}{c}{row.suffix}\" for c in choices]\n","        label   = int(row.answer) - 1\n","        return texts, label\n","\n","    def collate_fn(self, batch):\n","        texts, labels  = zip(*batch)\n","        flat = sum(texts, [])          # (B*5,) list\n","        enc  = self.tok(\n","            flat, padding=\"max_length\", truncation=True,\n","            max_length=self.max_len, return_tensors=\"pt\"\n","        )\n","        B = len(batch)\n","        return {\n","            \"input_ids\":     enc[\"input_ids\"].view(B, 5, -1),\n","            \"attention_mask\":enc[\"attention_mask\"].view(B, 5, -1),\n","            \"labels\":        torch.tensor(labels, dtype=torch.long)\n","        }\n","\n","# --------------------------------------------------------------------- #\n","# 2. Model: GPT-2 + LM-head to compute NLL\n","# --------------------------------------------------------------------- #\n","class NLLRankModel(nn.Module):\n","    def __init__(self, args):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained(\n","            model=args.model_size, d=args.d, l=args.l, num_heads=args.num_heads\n","        )\n","        vocab = GPT2Tokenizer.from_pretrained(args.model_size).vocab_size\n","        self.lm_head = nn.Linear(args.d, vocab, bias=False)\n","        for p in self.parameters(): p.requires_grad = True\n","\n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        input_ids: (B, C, L)   attention_mask: (B, C, L)\n","        returns nll: (B, C)  -- lower is better\n","        \"\"\"\n","        B, C, L = input_ids.shape\n","        flat_ids  = input_ids.view(B*C, L)\n","        flat_mask = attention_mask.view(B*C, L)\n","\n","        h = self.gpt(flat_ids, attention_mask=flat_mask)[\"last_hidden_state\"]\n","        logits = self.lm_head(h)                       # (B*C, L, V)\n","\n","        # shift for LM loss\n","        shift_logits = logits[:, :-1, :].contiguous()\n","        shift_labels = flat_ids[:, 1:].contiguous()\n","        shift_mask   = flat_mask[:, 1:].contiguous()\n","\n","        loss_ = F.cross_entropy(\n","            shift_logits.view(-1, shift_logits.size(-1)),\n","            shift_labels.view(-1),\n","            reduction=\"none\"\n","        ).view(flat_ids.size(0), -1) * shift_mask\n","\n","        # token average NLL\n","        nll = loss_.sum(1) / shift_mask.sum(1).clamp_min(1)   # (B*C,)\n","        return nll.view(B, C)                                 # (B,5)\n","\n","# --------------------------------------------------------------------- #\n","# 3. Train / Eval\n","# --------------------------------------------------------------------- #\n","def evaluate(loader, model, device):\n","    model.eval()\n","    tot = top1 = top2 = top3 = 0; tot_nll = 0.0\n","    with torch.no_grad():\n","        for batch in tqdm(loader, disable=TQDM_DISABLE, desc=\"Eval\"):\n","            ids, mask = batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device)\n","            nll = model(ids, mask)                 # (B, 5)\n","            scores = -nll                          # higher better\n","            rank = scores.argsort(dim=1, descending=True)\n","            y = batch[\"labels\"].to(device)\n","            B = y.size(0)\n","            top1 += (rank[:, 0] == y).sum().item()\n","            top2 += ((rank[:, :2] == y.unsqueeze(1)).any(1)).sum().item()\n","            top3 += ((rank[:, :3] == y.unsqueeze(1)).any(1)).sum().item()\n","            tot  += B\n","            tot_nll += nll.mean().item()*B\n","    return top1/tot, top2/tot, top3/tot, tot_nll/tot\n","\n","def train(args):\n","    seed_everything(args.seed)\n","    dev = torch.device(\"cuda\" if args.use_gpu and torch.cuda.is_available() else \"cpu\")\n","\n","    print(\"Device:\", dev)\n","\n","    # load data\n","    df  = pd.read_csv(args.data_path, encoding=\"utf-8-sig\")\n","    trn = df[df.split==\"train\"]; val = df[df.split==\"valid\"]\n","\n","    tok = GPT2Tokenizer.from_pretrained(args.model_size); tok.pad_token = tok.eos_token\n","    train_ds = AnswerDataset(trn, tok, args.max_length); val_ds = AnswerDataset(val, tok, args.max_length)\n","    tr_loader= DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,  collate_fn=train_ds.collate_fn)\n","    val_loader=DataLoader(val_ds,   batch_size=args.batch_size, shuffle=False, collate_fn=val_ds.collate_fn)\n","\n","    model = NLLRankModel(args).to(dev)\n","    optim = torch.optim.AdamW(model.parameters(), lr=args.lr)\n","    best = 0.0\n","\n","    for ep in range(1, args.epochs+1):\n","        model.train(); ep_loss = 0.0\n","        for batch in tqdm(tr_loader, disable=TQDM_DISABLE, desc=f\"Train {ep}\"):\n","            optim.zero_grad()\n","            ids, mask = batch[\"input_ids\"].to(dev), batch[\"attention_mask\"].to(dev)\n","            nll = model(ids, mask)           # (B,5)\n","            loss = F.cross_entropy(-nll, batch[\"labels\"].to(dev))\n","            loss.backward(); optim.step()\n","            ep_loss += loss.item()\n","        print(f\"Epoch {ep}  loss={ep_loss/len(tr_loader):.4f}\")\n","\n","        t1,t2,t3,av_nll = evaluate(val_loader, model, dev)\n","        print(f\"  Valid Top1/2/3={t1:.3f}/{t2:.3f}/{t3:.3f}  AvgNLL={av_nll:.3f}\")\n","        if t1>best: best=t1; save(model, optim, args)\n","\n","def save(m, o, args):\n","    os.makedirs(os.path.dirname(args.save_path), exist_ok=True)\n","    torch.save({\"model\":m.state_dict(),\"optim\":o.state_dict(),\"args\":args}, args.save_path)\n","    print(\"Saved to\", args.save_path)\n","\n","def get_args():\n","    p=argparse.ArgumentParser();  # identical to original\n","    p.add_argument(\"--data_path\", type=str, default=\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\")\n","    p.add_argument(\"--model_size\",type=str, default=\"gpt2\", choices=[\"gpt2\",\"gpt2-medium\",\"gpt2-large\"])\n","    p.add_argument(\"--batch_size\", type=int, default=4)\n","    p.add_argument(\"--max_length\", type=int, default=512)\n","    p.add_argument(\"--lr\",        type=float, default=5e-5)\n","    p.add_argument(\"--epochs\",    type=int, default=20)\n","    p.add_argument(\"--seed\",      type=int, default=42)\n","    p.add_argument(\"--use_gpu\",   action=\"store_true\")\n","    # Jupyter friendly\n","    args = p.parse_args([])\n","    if torch.cuda.is_available(): args.use_gpu = True\n","    if args.model_size==\"gpt2\":    args.d,args.l,args.num_heads=768,12,12\n","    elif args.model_size==\"gpt2-medium\": args.d,args.l,args.num_heads=1024,24,16\n","    else: args.d,args.l,args.num_heads=1280,36,20\n","    args.save_path=f\"/content/drive/MyDrive/CSEG321/models/answer_nll_{args.model_size}_{args.epochs}e.pt\"\n","    return args\n","\n","if __name__==\"__main__\":\n","    train(get_args())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":643,"referenced_widgets":["3f10f0a07f174a2487c1cd5cbafda8b4","16deb1606d2f4002adb9001c72767953","166bd2f9753c4bd3b064155e95cb08b5","d027255042214046b695caffeeeb04ee","3cf1bfd719854fdbb129d33d00e7997d","82c62261ca3648f5bdc3fa2c17e71929","07a268f8c80a4b2aac5d67172230dfbe","b527225a358d4d58982ecc92d2848fab","eb393767ffe14a29b067d8a011132963","a74af9f04dff46a2b4bd3476bef079ed","ae146e6c44bd4c53b1d12b6f78ce3b24","4a00b31a2f65405e831023c7417ffe40","b0c69eed3415401982faa6cf02cf0975","f9cef3e7099141979e44a15649d8cf2c","bbac7364e7b34fd684b92a16cb39df08","ad3628ffdc7f4bc5996e0c81f202924e","45c5a39075e447f8adfb48abc9072138","2c5331b25a514199a0d75a56bb386945","6f6510220cbb4eb69236f6416a6f4e39","ce92161b5b814bf1abbe6b0f32395a45","e46b1d365d4b4baea62a15900f569457","3d147d92e9c14c068c43395bf0af4956","9aa9e3ac72f540df83211c226819e3ad","775a0254f90c473ca51c9fdfb51cde29","a8d918b9db1c4c3fb034662105927320","5421d90c2f9a42be8055e2cde9d45e33","160a0210e80548c1a5fdad3e402b61d7","b34c9cb59fc344ee942e414f09ad47fa","e25b5ee261b84f0a832b70f04a88c797","66df474dbfe74b699a7adcc1f2d7f921","88678e1a726a43b7a0eafc46d8665418","0ef6366a33964660b64584f6a7049fb3","b614e3cc13a64f3e9e15fc2f05d02a99","6c3c9cc8591a4595bf444af490f31786","9590759c50c64c869f4b8a3a2695cf54","241f74a59cd647948f377bc030830b8c","30e9960354e94dc4b1b47e89a8f55c25","5e15aab1684443d19f1949172332a61e","409a340f6dd04d0ba87b532305a83814","3741855d7d1544f8ad94dfa8256b00ea","b6edfb42bf504bb386b9aef87f405816","87c893600d104d528ff13fd80472d0f0","0289faa1e96b49619600f7196ab8af89","c3cc5ab0ef20430888d13cf4c9bc6f88","6b722638ce304a58bacb95024c38fe42","685f13b468944dfa97f34d79f1ccd467","396fbd115b2748c3ae7ec2096efbfc9b","ea07fedbcc6e4125b6cd7729c19d0b12","15154c08d7154bb6812d3968ba64869c","cb72220408674ec28afbbea5ce84a4ee","9e8a0bd386a1462987348e8f124eccd9","c9a787231d124f269a1896f42f31c1c5","a891fd6f1853493f9d8206aea2804a90","8d1f8ef16e3849afb1a2f5f413d5ef71","2b30da5f434d4c20a2f54d64f6e8702b","9d89e762e4494325908a2ef13d4fa70c","024cc57f33fe4b7485f685005c105399","45b509cef6f041fdb2c9cf904645fed6","e8e43c43a1c34d4aac31d5596c8ec239","b3990df6293d40efbfe21d7f7e1807d6","c1e0cf27ea964326b654aa9d48a42f32","504a40c14a3642d09372454c50a281cc","a75acc64e52d4f59a3f63c4f811524c9","bd7fbce9d0a24b95884e255631c70ca3","5bc59cdf3b094b0baa8a381a928b399f","d78ae9d29c4f4e43a0f061047c1d3e4c"]},"id":"d5Pv8oqrCayX","outputId":"a3df8907-923e-4477-9f34-af6acfe28394"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f10f0a07f174a2487c1cd5cbafda8b4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a00b31a2f65405e831023c7417ffe40","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9aa9e3ac72f540df83211c226819e3ad","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c3c9cc8591a4595bf444af490f31786","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b722638ce304a58bacb95024c38fe42","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d89e762e4494325908a2ef13d4fa70c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Train1: 100%|██████████| 36/36 [00:18<00:00,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch1 loss=1.6603\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  5.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.278/0.444/0.556  AvgEntropy=1.609\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_dot_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train2: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch2 loss=1.6133\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.278/0.500/0.667  AvgEntropy=1.609\n"]},{"name":"stderr","output_type":"stream","text":["Train3: 100%|██████████| 36/36 [00:17<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch3 loss=1.6049\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.278/0.389/0.500  AvgEntropy=1.606\n"]},{"name":"stderr","output_type":"stream","text":["Train4: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch4 loss=1.6261\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.778/0.889  AvgEntropy=1.609\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_dot_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train5: 100%|██████████| 36/36 [00:17<00:00,  2.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch5 loss=1.6040\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.667/0.889/0.889  AvgEntropy=1.608\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_dot_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train6: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch6 loss=1.5537\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.444/0.722/0.889  AvgEntropy=1.570\n"]},{"name":"stderr","output_type":"stream","text":["Train7: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch7 loss=1.4577\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.278/0.722/0.944  AvgEntropy=1.517\n"]},{"name":"stderr","output_type":"stream","text":["Train8: 100%|██████████| 36/36 [00:17<00:00,  2.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch8 loss=1.4396\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.500/0.889/0.944  AvgEntropy=1.527\n"]},{"name":"stderr","output_type":"stream","text":["Train9: 100%|██████████| 36/36 [00:17<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch9 loss=1.3436\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.389/0.833/0.889  AvgEntropy=1.405\n"]},{"name":"stderr","output_type":"stream","text":["Train10: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch10 loss=1.2164\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.667/0.889/1.000  AvgEntropy=1.318\n"]},{"name":"stderr","output_type":"stream","text":["Train11: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch11 loss=1.1365\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.611/0.889/1.000  AvgEntropy=1.349\n"]},{"name":"stderr","output_type":"stream","text":["Train12: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch12 loss=1.1324\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.611/1.000/1.000  AvgEntropy=1.337\n"]},{"name":"stderr","output_type":"stream","text":["Train13: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch13 loss=1.0060\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.556/0.944/0.944  AvgEntropy=1.290\n"]},{"name":"stderr","output_type":"stream","text":["Train14: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch14 loss=0.8588\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.611/0.944/1.000  AvgEntropy=1.209\n"]},{"name":"stderr","output_type":"stream","text":["Train15: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch15 loss=0.9100\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.556/0.833/1.000  AvgEntropy=1.253\n"]},{"name":"stderr","output_type":"stream","text":["Train16: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch16 loss=0.7174\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.722/0.944/0.944  AvgEntropy=1.200\n","Saved to /content/drive/MyDrive/CSEG321/models/answer_dot_gpt2_20e.pt\n"]},{"name":"stderr","output_type":"stream","text":["Train17: 100%|██████████| 36/36 [00:17<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch17 loss=0.6561\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.722/0.944/1.000  AvgEntropy=1.210\n"]},{"name":"stderr","output_type":"stream","text":["Train18: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch18 loss=0.5209\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.611/1.000/1.000  AvgEntropy=1.113\n"]},{"name":"stderr","output_type":"stream","text":["Train19: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch19 loss=0.4985\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.556/0.889/1.000  AvgEntropy=1.157\n"]},{"name":"stderr","output_type":"stream","text":["Train20: 100%|██████████| 36/36 [00:16<00:00,  2.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch20 loss=0.4446\n"]},{"name":"stderr","output_type":"stream","text":["Eval: 100%|██████████| 5/5 [00:00<00:00,  6.21it/s]"]},{"name":"stdout","output_type":"stream","text":["  Valid Top1/2/3=0.556/0.833/0.944  AvgEntropy=1.176\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\"\"\"\n","Dot-Product Rank-Head Trainer\n","\n","Trains a GPT-2 encoder + linear rank head.\n","Top-1/2/3 accuracy + average softmax entropy on dev/test splits.\n","\"\"\"\n","\n","import argparse, os, random, sys\n","import numpy as np, pandas as pd, torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from transformers import GPT2Tokenizer\n","from models.gpt2 import GPT2Model\n","\n","TQDM_DISABLE=False\n","\n","# --------------------------------------------------------------------- #\n","def seed_everything(seed=42):\n","    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n","    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n","# --------------------------------------------------------------------- #\n","class AnswerDataset(Dataset):\n","    def __init__(self, df, tok, max_len=512):\n","        self.df, self.tok, self.max_len = df.reset_index(drop=True), tok, max_len\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        r=self.df.iloc[idx]\n","        choices=[r[f\"choice_{i}\"] for i in range(1,6)]\n","        texts=[f\"{r.prefix}{c}{r.suffix}\" for c in choices]\n","        lab=int(r.answer)-1\n","        return texts, lab\n","    def collate_fn(self,b):\n","        txts, labs=zip(*b); flat=sum(txts,[])\n","        enc=self.tok(flat,padding=\"max_length\",truncation=True,\n","                     max_length=self.max_len,return_tensors=\"pt\")\n","        B=len(b)\n","        return {\"input_ids\":enc.input_ids.view(B,5,-1),\n","                \"attention_mask\":enc.attention_mask.view(B,5,-1),\n","                \"labels\":torch.tensor(labs)}\n","# --------------------------------------------------------------------- #\n","class DotRankModel(nn.Module):\n","    def __init__(self,args):\n","        super().__init__()\n","        self.enc=GPT2Model.from_pretrained(model=args.model_size,\n","                                           d=args.d,l=args.l,num_heads=args.num_heads)\n","        self.head=nn.Linear(args.d,1)\n","        for p in self.parameters(): p.requires_grad=True\n","    def forward(self,ids,mask):\n","        B,C,L=ids.shape\n","        flat_ids,flat_mask=ids.view(B*C,L),mask.view(B*C,L)\n","        h=self.enc(flat_ids,attention_mask=flat_mask)[\"last_hidden_state\"]\n","        last_idx=flat_mask.sum(1)-1\n","        pooled=h[torch.arange(h.size(0)), last_idx]  # (B*C,d)\n","        score=self.head(pooled).view(B,C)            # (B,5)\n","        return score\n","# --------------------------------------------------------------------- #\n","def evaluate(loader,model,dev):\n","    model.eval(); tot=top1=top2=top3=0; tot_ent=0\n","    with torch.no_grad():\n","        for bt in tqdm(loader,disable=TQDM_DISABLE,desc=\"Eval\"):\n","            s=model(bt[\"input_ids\"].to(dev),bt[\"attention_mask\"].to(dev))\n","            rank=s.argsort(dim=1,descending=True)\n","            y=bt[\"labels\"].to(dev); B=y.size(0)\n","            top1+=(rank[:,0]==y).sum().item()\n","            top2+=((rank[:,:2]==y.unsqueeze(1)).any(1)).sum().item()\n","            top3+=((rank[:,:3]==y.unsqueeze(1)).any(1)).sum().item()\n","            tot+=B\n","            probs=F.softmax(s,dim=1)\n","            ent=-(probs*probs.log()).sum(1).mean().item()\n","            tot_ent+=ent*B\n","    return top1/tot,top2/tot,top3/tot,tot_ent/tot\n","# --------------------------------------------------------------------- #\n","def train(args):\n","    seed_everything(args.seed)\n","    dev=torch.device(\"cuda\" if args.use_gpu and torch.cuda.is_available() else \"cpu\")\n","    df=pd.read_csv(args.data_path,encoding=\"utf-8-sig\")\n","    tr,va=df[df.split==\"train\"],df[df.split==\"valid\"]\n","    tok=GPT2Tokenizer.from_pretrained(args.model_size); tok.pad_token=tok.eos_token\n","    tr_ds=AnswerDataset(tr,tok,args.max_length); va_ds=AnswerDataset(va,tok,args.max_length)\n","    tr_ld=DataLoader(tr_ds,batch_size=args.batch_size,shuffle=True,collate_fn=tr_ds.collate_fn)\n","    va_ld=DataLoader(va_ds,batch_size=args.batch_size,shuffle=False,collate_fn=va_ds.collate_fn)\n","\n","    model=DotRankModel(args).to(dev)\n","    opt=torch.optim.AdamW(model.parameters(),lr=args.lr)\n","    best=0\n","    for ep in range(1,args.epochs+1):\n","        model.train(); ep_loss=0\n","        for bt in tqdm(tr_ld,disable=TQDM_DISABLE,desc=f\"Train{ep}\"):\n","            opt.zero_grad()\n","            s=model(bt[\"input_ids\"].to(dev),bt[\"attention_mask\"].to(dev))\n","            loss=F.cross_entropy(s,bt[\"labels\"].to(dev))\n","            loss.backward(); opt.step()\n","            ep_loss+=loss.item()\n","        print(f\"Epoch{ep} loss={ep_loss/len(tr_ld):.4f}\")\n","        t1,t2,t3,ent=evaluate(va_ld,model,dev)\n","        print(f\"  Valid Top1/2/3={t1:.3f}/{t2:.3f}/{t3:.3f}  AvgEntropy={ent:.3f}\")\n","        if t1>best: best=t1; save(model,opt,args)\n","def save(m,o,args):\n","    os.makedirs(os.path.dirname(args.save_path),exist_ok=True)\n","    torch.save({\"model\":m.state_dict(),\"optim\":o.state_dict(),\"args\":args},args.save_path)\n","    print(\"Saved to\",args.save_path)\n","def get_args():\n","    p=argparse.ArgumentParser()\n","    p.add_argument(\"--data_path\",type=str,default=\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\")\n","    p.add_argument(\"--model_size\",type=str,default=\"gpt2\",choices=[\"gpt2\",\"gpt2-medium\",\"gpt2-large\"])\n","    p.add_argument(\"--batch_size\",type=int,default=4)\n","    p.add_argument(\"--max_length\",type=int,default=512)\n","    p.add_argument(\"--lr\",type=float,default=5e-5)\n","    p.add_argument(\"--epochs\",type=int,default=20)\n","    p.add_argument(\"--seed\",type=int,default=42)\n","    p.add_argument(\"--use_gpu\",action=\"store_true\")\n","    # Jupyter friendly\n","    args = p.parse_args([])\n","    if torch.cuda.is_available(): args.use_gpu = True\n","    if args.model_size==\"gpt2\": args.d,args.l,args.num_heads=768,12,12\n","    elif args.model_size==\"gpt2-medium\": args.d,args.l,args.num_heads=1024,24,16\n","    else: args.d,args.l,args.num_heads=1280,36,20\n","    args.save_path=f\"/content/drive/MyDrive/CSEG321/models/answer_dot_{args.model_size}_{args.epochs}e.pt\"\n","    return args\n","if __name__==\"__main__\": train(get_args())\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyO50GXPYldmHEuJz6gNPavv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"024cc57f33fe4b7485f685005c105399":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1e0cf27ea964326b654aa9d48a42f32","placeholder":"​","style":"IPY_MODEL_504a40c14a3642d09372454c50a281cc","value":"model.safetensors: 100%"}},"0289faa1e96b49619600f7196ab8af89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07a268f8c80a4b2aac5d67172230dfbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ef6366a33964660b64584f6a7049fb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15154c08d7154bb6812d3968ba64869c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"160a0210e80548c1a5fdad3e402b61d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"166bd2f9753c4bd3b064155e95cb08b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b527225a358d4d58982ecc92d2848fab","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb393767ffe14a29b067d8a011132963","value":26}},"16deb1606d2f4002adb9001c72767953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82c62261ca3648f5bdc3fa2c17e71929","placeholder":"​","style":"IPY_MODEL_07a268f8c80a4b2aac5d67172230dfbe","value":"tokenizer_config.json: 100%"}},"241f74a59cd647948f377bc030830b8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6edfb42bf504bb386b9aef87f405816","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87c893600d104d528ff13fd80472d0f0","value":1355256}},"2b30da5f434d4c20a2f54d64f6e8702b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c5331b25a514199a0d75a56bb386945":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30e9960354e94dc4b1b47e89a8f55c25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0289faa1e96b49619600f7196ab8af89","placeholder":"​","style":"IPY_MODEL_c3cc5ab0ef20430888d13cf4c9bc6f88","value":" 1.36M/1.36M [00:00&lt;00:00, 22.3MB/s]"}},"3741855d7d1544f8ad94dfa8256b00ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"396fbd115b2748c3ae7ec2096efbfc9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9a787231d124f269a1896f42f31c1c5","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a891fd6f1853493f9d8206aea2804a90","value":665}},"3cf1bfd719854fdbb129d33d00e7997d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d147d92e9c14c068c43395bf0af4956":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f10f0a07f174a2487c1cd5cbafda8b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16deb1606d2f4002adb9001c72767953","IPY_MODEL_166bd2f9753c4bd3b064155e95cb08b5","IPY_MODEL_d027255042214046b695caffeeeb04ee"],"layout":"IPY_MODEL_3cf1bfd719854fdbb129d33d00e7997d"}},"409a340f6dd04d0ba87b532305a83814":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b509cef6f041fdb2c9cf904645fed6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a75acc64e52d4f59a3f63c4f811524c9","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd7fbce9d0a24b95884e255631c70ca3","value":548105171}},"45c5a39075e447f8adfb48abc9072138":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a00b31a2f65405e831023c7417ffe40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0c69eed3415401982faa6cf02cf0975","IPY_MODEL_f9cef3e7099141979e44a15649d8cf2c","IPY_MODEL_bbac7364e7b34fd684b92a16cb39df08"],"layout":"IPY_MODEL_ad3628ffdc7f4bc5996e0c81f202924e"}},"504a40c14a3642d09372454c50a281cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5421d90c2f9a42be8055e2cde9d45e33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ef6366a33964660b64584f6a7049fb3","placeholder":"​","style":"IPY_MODEL_b614e3cc13a64f3e9e15fc2f05d02a99","value":" 456k/456k [00:00&lt;00:00, 16.6MB/s]"}},"5bc59cdf3b094b0baa8a381a928b399f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e15aab1684443d19f1949172332a61e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66df474dbfe74b699a7adcc1f2d7f921":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"685f13b468944dfa97f34d79f1ccd467":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb72220408674ec28afbbea5ce84a4ee","placeholder":"​","style":"IPY_MODEL_9e8a0bd386a1462987348e8f124eccd9","value":"config.json: 100%"}},"6b722638ce304a58bacb95024c38fe42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_685f13b468944dfa97f34d79f1ccd467","IPY_MODEL_396fbd115b2748c3ae7ec2096efbfc9b","IPY_MODEL_ea07fedbcc6e4125b6cd7729c19d0b12"],"layout":"IPY_MODEL_15154c08d7154bb6812d3968ba64869c"}},"6c3c9cc8591a4595bf444af490f31786":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9590759c50c64c869f4b8a3a2695cf54","IPY_MODEL_241f74a59cd647948f377bc030830b8c","IPY_MODEL_30e9960354e94dc4b1b47e89a8f55c25"],"layout":"IPY_MODEL_5e15aab1684443d19f1949172332a61e"}},"6f6510220cbb4eb69236f6416a6f4e39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"775a0254f90c473ca51c9fdfb51cde29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b34c9cb59fc344ee942e414f09ad47fa","placeholder":"​","style":"IPY_MODEL_e25b5ee261b84f0a832b70f04a88c797","value":"merges.txt: 100%"}},"82c62261ca3648f5bdc3fa2c17e71929":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87c893600d104d528ff13fd80472d0f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88678e1a726a43b7a0eafc46d8665418":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d1f8ef16e3849afb1a2f5f413d5ef71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9590759c50c64c869f4b8a3a2695cf54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_409a340f6dd04d0ba87b532305a83814","placeholder":"​","style":"IPY_MODEL_3741855d7d1544f8ad94dfa8256b00ea","value":"tokenizer.json: 100%"}},"9aa9e3ac72f540df83211c226819e3ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_775a0254f90c473ca51c9fdfb51cde29","IPY_MODEL_a8d918b9db1c4c3fb034662105927320","IPY_MODEL_5421d90c2f9a42be8055e2cde9d45e33"],"layout":"IPY_MODEL_160a0210e80548c1a5fdad3e402b61d7"}},"9d89e762e4494325908a2ef13d4fa70c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_024cc57f33fe4b7485f685005c105399","IPY_MODEL_45b509cef6f041fdb2c9cf904645fed6","IPY_MODEL_e8e43c43a1c34d4aac31d5596c8ec239"],"layout":"IPY_MODEL_b3990df6293d40efbfe21d7f7e1807d6"}},"9e8a0bd386a1462987348e8f124eccd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a74af9f04dff46a2b4bd3476bef079ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a75acc64e52d4f59a3f63c4f811524c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a891fd6f1853493f9d8206aea2804a90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8d918b9db1c4c3fb034662105927320":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66df474dbfe74b699a7adcc1f2d7f921","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88678e1a726a43b7a0eafc46d8665418","value":456318}},"ad3628ffdc7f4bc5996e0c81f202924e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae146e6c44bd4c53b1d12b6f78ce3b24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0c69eed3415401982faa6cf02cf0975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c5a39075e447f8adfb48abc9072138","placeholder":"​","style":"IPY_MODEL_2c5331b25a514199a0d75a56bb386945","value":"vocab.json: 100%"}},"b34c9cb59fc344ee942e414f09ad47fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3990df6293d40efbfe21d7f7e1807d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b527225a358d4d58982ecc92d2848fab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b614e3cc13a64f3e9e15fc2f05d02a99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6edfb42bf504bb386b9aef87f405816":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbac7364e7b34fd684b92a16cb39df08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e46b1d365d4b4baea62a15900f569457","placeholder":"​","style":"IPY_MODEL_3d147d92e9c14c068c43395bf0af4956","value":" 1.04M/1.04M [00:00&lt;00:00, 6.90MB/s]"}},"bd7fbce9d0a24b95884e255631c70ca3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1e0cf27ea964326b654aa9d48a42f32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3cc5ab0ef20430888d13cf4c9bc6f88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9a787231d124f269a1896f42f31c1c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb72220408674ec28afbbea5ce84a4ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce92161b5b814bf1abbe6b0f32395a45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d027255042214046b695caffeeeb04ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a74af9f04dff46a2b4bd3476bef079ed","placeholder":"​","style":"IPY_MODEL_ae146e6c44bd4c53b1d12b6f78ce3b24","value":" 26.0/26.0 [00:00&lt;00:00, 3.14kB/s]"}},"d78ae9d29c4f4e43a0f061047c1d3e4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e25b5ee261b84f0a832b70f04a88c797":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e46b1d365d4b4baea62a15900f569457":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8e43c43a1c34d4aac31d5596c8ec239":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bc59cdf3b094b0baa8a381a928b399f","placeholder":"​","style":"IPY_MODEL_d78ae9d29c4f4e43a0f061047c1d3e4c","value":" 548M/548M [00:01&lt;00:00, 580MB/s]"}},"ea07fedbcc6e4125b6cd7729c19d0b12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d1f8ef16e3849afb1a2f5f413d5ef71","placeholder":"​","style":"IPY_MODEL_2b30da5f434d4c20a2f54d64f6e8702b","value":" 665/665 [00:00&lt;00:00, 83.6kB/s]"}},"eb393767ffe14a29b067d8a011132963":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9cef3e7099141979e44a15649d8cf2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f6510220cbb4eb69236f6416a6f4e39","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce92161b5b814bf1abbe6b0f32395a45","value":1042301}}}}},"nbformat":4,"nbformat_minor":0}