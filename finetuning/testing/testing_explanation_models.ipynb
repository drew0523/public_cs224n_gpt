{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNtbrlJvqfsY3IjPI+y564/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ot4XL-Z_VsaG","executionInfo":{"status":"ok","timestamp":1749454569697,"user_tz":-540,"elapsed":105902,"user":{"displayName":"최승규","userId":"10957631576951172627"}},"outputId":"bb8c031c-b70f-4bd1-ed6f-dede7b0561d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["!git clone https://github.com/ItWasAllYellow/public_cs224n_gpt.git\n","%cd public_cs224n_gpt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVvgvRpIV2d5","executionInfo":{"status":"ok","timestamp":1749454583834,"user_tz":-540,"elapsed":2441,"user":{"displayName":"최승규","userId":"10957631576951172627"}},"outputId":"5605f8b9-8a14-4156-a09c-1c09ca1f894c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'public_cs224n_gpt'...\n","remote: Enumerating objects: 69, done.\u001b[K\n","remote: Counting objects: 100% (37/37), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 69 (delta 21), reused 13 (delta 13), pack-reused 32 (from 1)\u001b[K\n","Receiving objects: 100% (69/69), 30.87 MiB | 27.78 MiB/s, done.\n","Resolving deltas: 100% (22/22), done.\n","/content/public_cs224n_gpt\n"]}]},{"cell_type":"code","source":["# eval_margin_detailed.py\n","\"\"\"\n","Evaluate PPL-Margin model on test split with detailed stats:\n","  - Top-1/2/3 accuracy\n","  - For each choice:\n","      • selection ratio & count\n","      • correctness ratio (of times selected) & count correct\n","  - Overall accuracy & count\n","\"\"\"\n","import torch, pandas as pd, numpy as np\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer\n","from models.gpt2 import GPT2Model\n","from torch import nn\n","from tqdm import tqdm\n","\n","# 1) Dataset (same as training)\n","class AnswerMarginDataset(Dataset):\n","    def __init__(self, df, tok, max_length=512):\n","        self.df = df.reset_index(drop=True)\n","        self.tok = tok\n","        self.max_length = max_length\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        r = self.df.iloc[idx]\n","        choices = [r[f\"choice_{i}\"] for i in range(1,6)]\n","        texts = [f\"{r.prefix}{c}{r.suffix}\" for c in choices]\n","        label = int(r.answer) - 1\n","        return texts, label\n","    def collate_fn(self, batch):\n","        texts, labels = zip(*batch)\n","        flat = sum(texts, [])\n","        enc = self.tok(flat, padding=\"max_length\", truncation=True,\n","                       max_length=self.max_length, return_tensors=\"pt\")\n","        B = len(batch)\n","        return {\n","            \"input_ids\":      enc.input_ids.view(B,5,-1),\n","            \"attention_mask\": enc.attention_mask.view(B,5,-1),\n","            \"labels\":         torch.tensor(labels, dtype=torch.long)\n","        }\n","\n","# 2) Model + PPL fn\n","class AnswerMarginModel(nn.Module):\n","    def __init__(self, args):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained(\n","            model=args.model_size, d=args.d, l=args.l, num_heads=args.num_heads)\n","        self.lm_head = nn.Linear(args.d,\n","            GPT2Tokenizer.from_pretrained(args.model_size).vocab_size, bias=False)\n","    def forward(self, ids, mask):\n","        B,C,L = ids.shape\n","        flat_ids = ids.view(B*C, L)\n","        flat_mask= mask.view(B*C, L)\n","        h = self.gpt(flat_ids, attention_mask=flat_mask)[\"last_hidden_state\"]\n","        logits = self.lm_head(h)\n","        sl, lbl, sm = logits[:,:-1,:], flat_ids[:,1:], flat_mask[:,1:]\n","        loss = F.cross_entropy(\n","            sl.reshape(-1, sl.size(-1)),\n","            lbl.reshape(-1),\n","            reduction=\"none\"\n","        ).view(B*C, -1) * sm\n","        nll = loss.sum(1) / sm.sum(1).clamp_min(1)\n","        return nll.view(B, C)\n","\n","# 3) Load\n","class Args: pass\n","args = Args()\n","args.model_size = \"gpt2\"\n","args.d, args.l, args.num_heads = 768,12,12\n","checkpoint = torch.load(\n","    \"/content/drive/MyDrive/CSEG321/models/answer_margin_gpt2_20e_5e-05lr.pt\",\n","    map_location=\"cpu\", weights_only=False\n",")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tok = GPT2Tokenizer.from_pretrained(args.model_size)\n","tok.pad_token = tok.eos_token\n","model = AnswerMarginModel(args).to(device)\n","model.load_state_dict(checkpoint[\"model\"])\n","model.eval()\n","\n","# 4) DataLoader\n","df = pd.read_csv(\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\", encoding=\"utf-8-sig\")\n","test_df = df[df.split==\"test\"]\n","ds = AnswerMarginDataset(test_df, tok, max_length=512)\n","loader = DataLoader(ds, batch_size=4, shuffle=False, collate_fn=ds.collate_fn)\n","\n","# 5) Evaluate with detailed stats\n","total = 0\n","correct_overall = 0\n","top1 = top2 = top3 = 0\n","selected_counts = np.zeros(5, dtype=int)\n","correct_counts = np.zeros(5, dtype=int)\n","\n","with torch.no_grad():\n","    for batch in tqdm(loader):\n","        ids = batch[\"input_ids\"].to(device)\n","        mask= batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        nll = model(ids, mask)            # (B,5)\n","        scores = -nll\n","        rank = scores.argsort(dim=1, descending=True)\n","        B = labels.size(0)\n","\n","        total += B\n","        top1 += (rank[:,0]==labels).sum().item()\n","        top2 += ((rank[:,:2]==labels.unsqueeze(1)).any(1)).sum().item()\n","        top3 += ((rank[:,:3]==labels.unsqueeze(1)).any(1)).sum().item()\n","\n","        for i in range(B):\n","            pred = rank[i,0].item()\n","            selected_counts[pred] += 1\n","            if pred == labels[i].item():\n","                correct_counts[pred] += 1\n","                correct_overall += 1\n","\n","# overall accuracy\n","overall_acc = correct_overall / total\n","\n","print(\"\\nAnswer Model - PPL Margin\")\n","print(f\"Overall accuracy: {overall_acc*100:.2f}% ({correct_overall}/{total})\")\n","print(f\"Top-1 accuracy:     {top1/total*100:.2f}%\")\n","print(f\"Top-2 accuracy:     {top2/total*100:.2f}%\")\n","print(f\"Top-3 accuracy:     {top3/total*100:.2f}%\\n\")\n","\n","print(\"Choice statistics:\")\n","for idx in range(5):\n","    sel_count = selected_counts[idx]\n","    sel_ratio = sel_count / total * 100\n","    corr_count = correct_counts[idx]\n","    # avoid zero-division\n","    corr_ratio = corr_count / sel_count * 100 if sel_count>0 else 0.0\n","    print(f\" Choice {idx+1}: selected {sel_ratio:.2f}% ({sel_count} times) / \"\n","          f\"correct {corr_ratio:.2f}% ({corr_count} times)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPXxQxBHV1XK","executionInfo":{"status":"ok","timestamp":1749454891099,"user_tz":-540,"elapsed":5855,"user":{"displayName":"최승규","userId":"10957631576951172627"}},"outputId":"ff99ae3d-35ce-4dae-99ae-18b73c87e17a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:01<00:00,  4.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Answer Model - PPL Margin\n","Overall accuracy: 5.56% (1/18)\n","Top-1 accuracy:     5.56%\n","Top-2 accuracy:     27.78%\n","Top-3 accuracy:     38.89%\n","\n","Choice statistics:\n"," Choice 1: selected 11.11% (2 times) / correct 0.00% (0 times)\n"," Choice 2: selected 27.78% (5 times) / correct 20.00% (1 times)\n"," Choice 3: selected 16.67% (3 times) / correct 0.00% (0 times)\n"," Choice 4: selected 22.22% (4 times) / correct 0.00% (0 times)\n"," Choice 5: selected 22.22% (4 times) / correct 0.00% (0 times)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# eval_nllranking_detailed.py\n","\"\"\"\n","Evaluate NLL-Ranking model on test split with detailed stats:\n","  - Top-1/2/3 accuracy\n","  - For each choice:\n","      • selection ratio & count\n","      • correctness ratio (of times selected) & count correct\n","  - Overall accuracy & count\n","\"\"\"\n","import torch, pandas as pd, numpy as np\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer\n","from models.gpt2 import GPT2Model\n","from torch import nn\n","from tqdm import tqdm\n","\n","class AnswerDataset(Dataset):\n","    def __init__(self, df, tok, max_len=512):\n","        self.df, self.tok, self.max_len = df.reset_index(drop=True), tok, max_len\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        r = self.df.iloc[idx]\n","        choices = [r[f\"choice_{i}\"] for i in range(1,6)]\n","        texts   = [f\"{r.prefix}{c}{r.suffix}\" for c in choices]\n","        label   = int(r.answer) - 1\n","        return texts, label\n","    def collate_fn(self, batch):\n","        texts, labels = zip(*batch)\n","        flat = sum(texts, [])\n","        enc = self.tok(flat,\n","                       padding=\"max_length\",\n","                       truncation=True,\n","                       max_length=self.max_len,\n","                       return_tensors=\"pt\")\n","        B = len(batch)\n","        return {\n","            \"input_ids\":      enc.input_ids.view(B,5,-1),\n","            \"attention_mask\": enc.attention_mask.view(B,5,-1),\n","            \"labels\":         torch.tensor(labels, dtype=torch.long)\n","        }\n","\n","class NLLRankModel(nn.Module):\n","    def __init__(self, args):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained(\n","            model=args.model_size, d=args.d, l=args.l, num_heads=args.num_heads)\n","        vocab = GPT2Tokenizer.from_pretrained(args.model_size).vocab_size\n","        self.lm_head = nn.Linear(args.d, vocab, bias=False)\n","    def forward(self, ids, mask):\n","        B,C,L = ids.shape\n","        flat_ids  = ids.view(B*C, L)\n","        flat_mask = mask.view(B*C, L)\n","        h = self.gpt(flat_ids, attention_mask=flat_mask)[\"last_hidden_state\"]\n","        logits = self.lm_head(h)\n","        sl, lbl, sm = logits[:,:-1,:], flat_ids[:,1:], flat_mask[:,1:]\n","        loss = F.cross_entropy(\n","            sl.reshape(-1, sl.size(-1)),\n","            lbl.reshape(-1),\n","            reduction=\"none\"\n","        ).view(B*C, -1) * sm\n","        nll = loss.sum(1) / sm.sum(1).clamp_min(1)\n","        return nll.view(B, C)\n","\n","# Load\n","class Args: pass\n","args = Args()\n","args.model_size = \"gpt2\"\n","args.d, args.l, args.num_heads = 768,12,12\n","\n","ckpt = torch.load(\n","    \"/content/drive/MyDrive/CSEG321/models/answer_nll_gpt2_20e.pt\",\n","    map_location=\"cpu\", weights_only=False\n",")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tok = GPT2Tokenizer.from_pretrained(args.model_size)\n","tok.pad_token = tok.eos_token\n","model = NLLRankModel(args).to(device)\n","model.load_state_dict(ckpt[\"model\"])\n","model.eval()\n","\n","# Data\n","df = pd.read_csv(\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\", encoding=\"utf-8-sig\")\n","test_df = df[df.split==\"test\"]\n","ds = AnswerDataset(test_df, tok)\n","loader = DataLoader(ds, batch_size=4, shuffle=False, collate_fn=ds.collate_fn)\n","\n","# Evaluate detailed stats\n","total = 0\n","correct_overall = 0\n","top1 = top2 = top3 = 0\n","selected_counts = np.zeros(5, dtype=int)\n","correct_counts  = np.zeros(5, dtype=int)\n","\n","with torch.no_grad():\n","    for batch in tqdm(loader):\n","        ids    = batch[\"input_ids\"].to(device)\n","        mask   = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        nll = model(ids, mask)           # (B,5)\n","        scores = -nll\n","        rank = scores.argsort(dim=1, descending=True)\n","        B = labels.size(0)\n","\n","        total += B\n","        top1  += (rank[:,0] == labels).sum().item()\n","        top2  += ((rank[:,:2] == labels.unsqueeze(1)).any(1)).sum().item()\n","        top3  += ((rank[:,:3] == labels.unsqueeze(1)).any(1)).sum().item()\n","\n","        for i in range(B):\n","            pred = rank[i,0].item()\n","            selected_counts[pred] += 1\n","            if pred == labels[i].item():\n","                correct_counts[pred] += 1\n","                correct_overall += 1\n","\n","# Overall accuracy\n","overall_acc = correct_overall / total\n","\n","print(\"\\nAnswer Model - Negative Log Likelihood\")\n","print(f\"Overall accuracy: {overall_acc*100:.2f}% ({correct_overall}/{total})\")\n","print(f\"Top-1 accuracy:     {top1/total*100:.2f}%\")\n","print(f\"Top-2 accuracy:     {top2/total*100:.2f}%\")\n","print(f\"Top-3 accuracy:     {top3/total*100:.2f}%\\n\")\n","\n","print(\"Choice statistics:\")\n","for idx in range(5):\n","    sel_count = selected_counts[idx]\n","    sel_ratio = sel_count / total * 100\n","    corr_count = correct_counts[idx]\n","    corr_ratio = (corr_count / sel_count * 100) if sel_count>0 else 0.0\n","    print(f\" Choice {idx+1}: selected {sel_ratio:.2f}% ({sel_count} times) / \"\n","          f\"correct {corr_ratio:.2f}% ({corr_count} times)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2E68s44Wvx1","executionInfo":{"status":"ok","timestamp":1749454942007,"user_tz":-540,"elapsed":19327,"user":{"displayName":"최승규","userId":"10957631576951172627"}},"outputId":"daa2d932-04bf-4603-9db1-be901fa36f21"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:01<00:00,  4.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Answer Model - Negative Log Likelihood\n","Overall accuracy: 27.78% (5/18)\n","Top-1 accuracy:     27.78%\n","Top-2 accuracy:     38.89%\n","Top-3 accuracy:     61.11%\n","\n","Choice statistics:\n"," Choice 1: selected 16.67% (3 times) / correct 66.67% (2 times)\n"," Choice 2: selected 22.22% (4 times) / correct 25.00% (1 times)\n"," Choice 3: selected 16.67% (3 times) / correct 33.33% (1 times)\n"," Choice 4: selected 27.78% (5 times) / correct 0.00% (0 times)\n"," Choice 5: selected 16.67% (3 times) / correct 33.33% (1 times)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# eval_dotrank_detailed.py\n","\"\"\"\n","Evaluate Dot-Product Rank-Head model on test split with detailed stats:\n","  - Top-1/2/3 accuracy\n","  - For each choice:\n","      • selection ratio & count\n","      • correctness ratio (of times selected) & count correct\n","  - Overall accuracy & count\n","\"\"\"\n","import torch, pandas as pd, numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer\n","from models.gpt2 import GPT2Model\n","import torch.nn.functional as F\n","from torch import nn\n","from tqdm import tqdm\n","from collections import OrderedDict\n","\n","class AnswerDataset(Dataset):\n","    def __init__(self, df, tok, max_len=512):\n","        self.df, self.tok, self.max_len = df.reset_index(drop=True), tok, max_len\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        r = self.df.iloc[idx]\n","        choices = [r[f\"choice_{i}\"] for i in range(1,6)]\n","        texts   = [f\"{r.prefix}{c}{r.suffix}\" for c in choices]\n","        label   = int(r.answer) - 1\n","        return texts, label\n","    def collate_fn(self, batch):\n","        txts, labs = zip(*batch)\n","        flat = sum(txts, [])\n","        enc = self.tok(\n","            flat,\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=self.max_len,\n","            return_tensors=\"pt\"\n","        )\n","        B = len(batch)\n","        return {\n","            \"input_ids\":      enc.input_ids.view(B, 5, -1),\n","            \"attention_mask\": enc.attention_mask.view(B, 5, -1),\n","            \"labels\":         torch.tensor(labs, dtype=torch.long)\n","        }\n","\n","class DotRankModel(nn.Module):\n","    def __init__(self, args):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained(\n","            model=args.model_size, d=args.d, l=args.l, num_heads=args.num_heads\n","        )\n","        self.head = nn.Linear(args.d, 1)\n","    def forward(self, ids, mask):\n","        B, C, L = ids.shape\n","        flat_ids  = ids.view(B*C, L)\n","        flat_mask = mask.view(B*C, L)\n","        h = self.gpt(flat_ids, attention_mask=flat_mask)[\"last_hidden_state\"]\n","        last_idx = (flat_mask.sum(dim=1) - 1).long()\n","        rep = h[torch.arange(h.size(0)), last_idx]  # (B*C, d)\n","        scores = self.head(rep).view(B, C)           # (B,5)\n","        return scores\n","\n","# --------------------------------------------------------------------- #\n","# Load & prepare model\n","# --------------------------------------------------------------------- #\n","class Args: pass\n","args = Args()\n","args.model_size = \"gpt2\"\n","args.d, args.l, args.num_heads = 768, 12, 12\n","\n","ckpt = torch.load(\n","    \"/content/drive/MyDrive/CSEG321/models/answer_dot_gpt2_20e.pt\",\n","    map_location=\"cpu\",\n","    weights_only=False\n",")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","tok = GPT2Tokenizer.from_pretrained(args.model_size)\n","tok.pad_token = tok.eos_token\n","\n","model = DotRankModel(args).to(device)\n","\n","# rename 'enc.' keys to 'gpt.' if needed\n","orig_sd = ckpt[\"model\"]\n","new_sd = OrderedDict()\n","for k, v in orig_sd.items():\n","    if k.startswith(\"enc.\"):\n","        new_k = \"gpt.\" + k[len(\"enc.\"):]\n","    else:\n","        new_k = k\n","    new_sd[new_k] = v\n","model.load_state_dict(new_sd)\n","model.eval()\n","\n","# prepare data\n","df = pd.read_csv(\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\", encoding=\"utf-8-sig\")\n","test_df = df[df.split == \"test\"]\n","ds = AnswerDataset(test_df, tok)\n","loader = DataLoader(ds, batch_size=4, shuffle=False, collate_fn=ds.collate_fn)\n","\n","# --------------------------------------------------------------------- #\n","# Evaluate detailed stats\n","# --------------------------------------------------------------------- #\n","total = 0\n","correct_overall = 0\n","top1 = top2 = top3 = 0\n","selected_counts = np.zeros(5, dtype=int)\n","correct_counts  = np.zeros(5, dtype=int)\n","\n","with torch.no_grad():\n","    for batch in tqdm(loader, desc=\"Evaluating\", disable=False):\n","        ids    = batch[\"input_ids\"].to(device)\n","        mask   = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","        B = labels.size(0)\n","\n","        scores = model(ids, mask)            # (B,5)\n","        rank = scores.argsort(dim=1, descending=True)\n","\n","        total += B\n","        top1  += (rank[:, 0] == labels).sum().item()\n","        top2  += ((rank[:, :2] == labels.unsqueeze(1)).any(1)).sum().item()\n","        top3  += ((rank[:, :3] == labels.unsqueeze(1)).any(1)).sum().item()\n","\n","        for i in range(B):\n","            pred = rank[i, 0].item()\n","            selected_counts[pred] += 1\n","            if pred == labels[i].item():\n","                correct_counts[pred] += 1\n","                correct_overall += 1\n","\n","# print results\n","overall_acc = correct_overall / total\n","print(\"\\nAnswer Model - Dot Product\")\n","print(f\"Overall accuracy: {overall_acc*100:.2f}% ({correct_overall}/{total})\")\n","print(f\"Top-1 accuracy:     {top1/total*100:.2f}%\")\n","print(f\"Top-2 accuracy:     {top2/total*100:.2f}%\")\n","print(f\"Top-3 accuracy:     {top3/total*100:.2f}%\\n\")\n","\n","print(\"Choice statistics:\")\n","for idx in range(5):\n","    sel_count = selected_counts[idx]\n","    sel_ratio = sel_count / total * 100\n","    corr_count = correct_counts[idx]\n","    corr_ratio = (corr_count / sel_count * 100) if sel_count > 0 else 0.0\n","    print(f\" Choice {idx+1}: selected {sel_ratio:.2f}% ({sel_count} times) / \"\n","          f\"correct {corr_ratio:.2f}% ({corr_count} times)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRl5rzQUW2R3","executionInfo":{"status":"ok","timestamp":1749455012491,"user_tz":-540,"elapsed":11088,"user":{"displayName":"최승규","userId":"10957631576951172627"}},"outputId":"bbe50a35-a43c-4bb3-ddfa-5170b1f70b58"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 5/5 [00:00<00:00,  5.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Answer Model - Dot Product\n","Overall accuracy: 38.89% (7/18)\n","Top-1 accuracy:     38.89%\n","Top-2 accuracy:     55.56%\n","Top-3 accuracy:     77.78%\n","\n","Choice statistics:\n"," Choice 1: selected 33.33% (6 times) / correct 50.00% (3 times)\n"," Choice 2: selected 16.67% (3 times) / correct 33.33% (1 times)\n"," Choice 3: selected 16.67% (3 times) / correct 33.33% (1 times)\n"," Choice 4: selected 11.11% (2 times) / correct 0.00% (0 times)\n"," Choice 5: selected 22.22% (4 times) / correct 50.00% (2 times)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# eval_pretrained_gpt2_detailed.py\n","\"\"\"\n","Evaluate vanilla pretrained GPT-2 (no fine-tuning) on test split with detailed stats:\n","  - Top-1/2/3 accuracy\n","  - For each choice:\n","      • selection ratio & count\n","      • correctness ratio (of times selected) & count correct\n","  - Overall accuracy & count\n","\"\"\"\n","import torch\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from tqdm import tqdm\n","\n","class AnswerDataset(Dataset):\n","    def __init__(self, df, tok, max_len=512):\n","        self.df, self.tok, self.max_len = df.reset_index(drop=True), tok, max_len\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, idx):\n","        r = self.df.iloc[idx]\n","        choices = [r[f\"choice_{i}\"] for i in range(1,6)]\n","        texts   = [f\"{r.prefix}{c}{r.suffix}\" for c in choices]\n","        label   = int(r.answer) - 1\n","        return texts, label\n","    def collate_fn(self, batch):\n","        txts, labs = zip(*batch)\n","        flat = sum(txts, [])\n","        enc = self.tok(flat,\n","                       padding=\"max_length\",\n","                       truncation=True,\n","                       max_length=self.max_len,\n","                       return_tensors=\"pt\")\n","        B = len(batch)\n","        return {\n","            \"input_ids\":      enc.input_ids.view(B, 5, -1),\n","            \"attention_mask\": enc.attention_mask.view(B, 5, -1),\n","            \"labels\":         torch.tensor(labs, dtype=torch.long)\n","        }\n","\n","def evaluate_pretrained(args):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_gpu else \"cpu\")\n","\n","    # load model & tokenizer\n","    tok = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","    tok.pad_token = tok.eos_token\n","    model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n","    model.eval()\n","\n","    # load test data\n","    df = pd.read_csv(args.data_path, encoding=\"utf-8-sig\")\n","    test_df = df[df.split == \"test\"]\n","    ds = AnswerDataset(test_df, tok, max_len=args.max_length)\n","    loader = DataLoader(ds, batch_size=args.batch_size, shuffle=False, collate_fn=ds.collate_fn)\n","\n","    total = 0\n","    correct_overall = 0\n","    top1 = top2 = top3 = 0\n","    selected_counts = np.zeros(5, dtype=int)\n","    correct_counts  = np.zeros(5, dtype=int)\n","\n","    with torch.no_grad():\n","        for batch in tqdm(loader, desc=\"Eval pretrained GPT2\"):\n","            B, C, L = batch[\"input_ids\"].shape\n","            ids  = batch[\"input_ids\"].view(B*C, L).to(device)\n","            mask = batch[\"attention_mask\"].view(B*C, L).to(device)\n","            labels = batch[\"labels\"].to(device)\n","\n","            # compute per-sequence NLL sum\n","            shift_mask  = mask[:,1:]\n","            token_count = shift_mask.sum(dim=1).clamp_min(1)\n","            loss = model(input_ids=ids, attention_mask=mask, labels=ids).loss\n","            nll_sum = loss * token_count   # shape (B*C,)\n","\n","            scores = -nll_sum.view(B, C)   # (B,5)\n","            rank = scores.argsort(dim=1, descending=True)\n","\n","            total += B\n","            top1  += (rank[:,0] == labels).sum().item()\n","            top2  += ((rank[:,:2] == labels.unsqueeze(1)).any(1)).sum().item()\n","            top3  += ((rank[:,:3] == labels.unsqueeze(1)).any(1)).sum().item()\n","\n","            for i in range(B):\n","                pred = rank[i,0].item()\n","                selected_counts[pred] += 1\n","                if pred == labels[i].item():\n","                    correct_counts[pred] += 1\n","                    correct_overall += 1\n","\n","    # summarize\n","    overall_acc = correct_overall / total\n","    print(\"\\nAnswer Model - No Fine Tuning\")\n","    print(f\"Overall accuracy: {overall_acc*100:.2f}% ({correct_overall}/{total})\")\n","    print(f\"Top-1 accuracy:     {top1/total*100:.2f}%\")\n","    print(f\"Top-2 accuracy:     {top2/total*100:.2f}%\")\n","    print(f\"Top-3 accuracy:     {top3/total*100:.2f}%\\n\")\n","\n","    print(\"Choice statistics:\")\n","    for idx in range(5):\n","        sel_count = selected_counts[idx]\n","        sel_ratio = sel_count / total * 100\n","        corr_count = correct_counts[idx]\n","        corr_ratio = (corr_count / sel_count * 100) if sel_count > 0 else 0.0\n","        print(f\" Choice {idx+1}: selected {sel_ratio:.2f}% ({sel_count} times) / \"\n","              f\"correct {corr_ratio:.2f}% ({corr_count} times)\")\n","\n","if __name__ == \"__main__\":\n","    import argparse\n","    p = argparse.ArgumentParser()\n","    p.add_argument(\"--data_path\",  type=str, default=\"/content/drive/MyDrive/CSEG321/dataset/answer_margin.csv\")\n","    p.add_argument(\"--batch_size\", type=int, default=4)\n","    p.add_argument(\"--max_length\", type=int, default=512)\n","    p.add_argument(\"--use_gpu\",    action=\"store_true\")\n","    args = p.parse_args([])\n","    evaluate_pretrained(args)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKneVg9La3DF","executionInfo":{"status":"ok","timestamp":1749455271177,"user_tz":-540,"elapsed":33282,"user":{"displayName":"최승규","userId":"10957631576951172627"}},"outputId":"92d8a04b-5d8e-4bbe-de31-b5d3d660d9a8"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Eval pretrained GPT2:   0%|          | 0/5 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","Eval pretrained GPT2: 100%|██████████| 5/5 [00:32<00:00,  6.50s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Answer Model - No Fine Tuning\n","Overall accuracy: 33.33% (6/18)\n","Top-1 accuracy:     33.33%\n","Top-2 accuracy:     61.11%\n","Top-3 accuracy:     77.78%\n","\n","Choice statistics:\n"," Choice 1: selected 77.78% (14 times) / correct 42.86% (6 times)\n"," Choice 2: selected 0.00% (0 times) / correct 0.00% (0 times)\n"," Choice 3: selected 5.56% (1 times) / correct 0.00% (0 times)\n"," Choice 4: selected 16.67% (3 times) / correct 0.00% (0 times)\n"," Choice 5: selected 0.00% (0 times) / correct 0.00% (0 times)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}